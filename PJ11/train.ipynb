{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b944a458-ac67-4501-b233-3a270d39f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import configparser\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, datasets\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3a1a91-a0e4-47e1-a93f-58ab4ad315f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"your_model_name.pth\"\n",
    "data_dir = \"./test\"\n",
    "batch_size = 32\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea3acf6-285c-48d7-98b0-ad752c1bf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_norm(dataset):\n",
    "#     # dataset의 axis=1, 2에 대한 평균 산출\n",
    "#     mean_ = np.array([np.mean(x.numpy(), axis=(1, 2)) for x, _ in dataset])\n",
    "#     # r, g, b 채널에 대한 각각의 평균 산출\n",
    "#     mean_r = mean_[:, 0].mean()\n",
    "#     mean_g = mean_[:, 1].mean()\n",
    "#     mean_b = mean_[:, 2].mean()\n",
    "\n",
    "#     # dataset의 axis=1, 2에 대한 표준편차 산출\n",
    "#     std_ = np.array([np.std(x.numpy(), axis=(1, 2)) for x, _ in dataset])\n",
    "#     # r, g, b 채널에 대한 각각의 표준편차 산출\n",
    "#     std_r = std_[:, 0].mean()\n",
    "#     std_g = std_[:, 1].mean()\n",
    "#     std_b = std_[:, 2].mean()\n",
    "    \n",
    "#     return (mean_r, mean_g, mean_b), (std_r, std_g, std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187ac7b6-25a3-473f-bbed-1b8f1c8d4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(root=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09bf9a89-551d-448a-a730-3568a0d83f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_, std_ = calculate_norm(train_dataset)\n",
    "# mean_ = np.around(mean_, 3)\n",
    "# std_ = np.around(std_, 3)\n",
    "# print(f'평균(R,G,B): {mean_}\\n표준편차(R,G,B): {std_}')\n",
    "# transforms_set = {\"resize\": (384, 384), \"normalize\": (list(mean_), list(std_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf1be04-91d3-4a85-a45e-d879499b4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = [0.485, 0.456, 0.406]\n",
    "std_ = [0.229, 0.224, 0.225]\n",
    "transforms_set = {\"resize\": (384, 384), \"normalize\": (list(mean_), list(std_))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713a6625-6157-45a9-a9cd-a3109ff0a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.485, 0.456, 0.406]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291c4887-281b-41d0-a5ce-b36c00767c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.229, 0.224, 0.225]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(std_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ecc314a-79be-4200-bb30-892cc9c894bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=list(mean_), std=list(std_)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8a30a5-c074-4b5f-b483-fdf17e7f0ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : {0: 'NG', 1: 'OK'}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root=data_dir, transform=transform_train)\n",
    "idx_to_cls = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "\n",
    "print(f\"class : {idx_to_cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52efeaa9-3ed5-4c90-8e7f-ac74ede49270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3012b96f-4bf4-4f76-8a70-b685f22b0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터셋에도 동일한 변환 적용\n",
    "val_dataset.dataset.transform = transform_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b22c37e-2dde-4638-9c72-dae39b60b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6567bbbe-8797-4a37-a7e1-ea4c819c23bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes : 2\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_v2_s(weights=None)\n",
    "\n",
    "class_folder_dir = glob.glob(data_dir + \"/*\")\n",
    "num_classes = len(class_folder_dir)  # Change to your number of classes\n",
    "print(f\"number of classes : {num_classes}\")\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad7970e-cf6e-45a3-a526-03c951d2b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a9f7d2-e8e2-4bbd-899f-1410f8713b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./config\"):\n",
    "    os.makedirs(\"./config\")\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.add_section(str(model_name.split(\".\")[0]))\n",
    "config.set(str(model_name.split(\".\")[0]), \"model_name\", model_name)\n",
    "config.set(str(model_name.split(\".\")[0]), \"transforms\", str(transforms_set))\n",
    "config.set(str(model_name.split(\".\")[0]), \"idx_to_cls\", str(idx_to_cls))\n",
    "config.set(str(model_name.split(\".\")[0]), \"num_classes\", str(num_classes))\n",
    "\n",
    "with open(\"./config/config.ini\", \"a\") as f:\n",
    "    config.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098dd7c8-f939-4049-962e-663cdd67b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_model(train_loader, val_loader, model, criterion, optimizer, num_epochs=25):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with tqdm(train_loader, ncols=160, ascii=\" =\", unit=\"batch\") as tepoch:\n",
    "            for inputs, labels in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
    "              f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # 모델 저장 조건 추가: 현재 검증 정확도가 지금까지의 최고보다 더 높으면 모델 저장\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c25e0733-13de-4a68-8d0a-d39afb0f632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|==                                                                                                 | 7/234 [00:09<04:55,  1.30s/batch, loss=0.503]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_and_validate_model(train_loader, val_loader, model, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4dfce22-728b-4d98-b5ea-a9f8dbd16292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear GPU MEM\n",
    "# for p in model.parameters():\n",
    "#     if p.grad is not None:\n",
    "#         del p.grad \n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
